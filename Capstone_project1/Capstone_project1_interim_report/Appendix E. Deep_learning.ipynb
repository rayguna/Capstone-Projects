{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML -multilabel classification\n",
    "\n",
    "- Using multilearn API  \n",
    "ref.: https://www.analyticsvidhya.com/blog/2017/08/introduction-to-multi-label-classification/\n",
    "\n",
    "- using onehotencoder for multilabel classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (I) Import and prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>600</th>\n",
       "      <th>604</th>\n",
       "      <th>608</th>\n",
       "      <th>612</th>\n",
       "      <th>616</th>\n",
       "      <th>620</th>\n",
       "      <th>624</th>\n",
       "      <th>628</th>\n",
       "      <th>632</th>\n",
       "      <th>...</th>\n",
       "      <th>3464</th>\n",
       "      <th>3468</th>\n",
       "      <th>3472</th>\n",
       "      <th>3476</th>\n",
       "      <th>3480</th>\n",
       "      <th>3484</th>\n",
       "      <th>3488</th>\n",
       "      <th>3492</th>\n",
       "      <th>3496</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1119-40-0</td>\n",
       "      <td>0.009480</td>\n",
       "      <td>0.011373</td>\n",
       "      <td>0.008950</td>\n",
       "      <td>0.010881</td>\n",
       "      <td>0.012741</td>\n",
       "      <td>0.012765</td>\n",
       "      <td>0.011669</td>\n",
       "      <td>0.010218</td>\n",
       "      <td>0.008583</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007078</td>\n",
       "      <td>0.007871</td>\n",
       "      <td>0.009175</td>\n",
       "      <td>0.010160</td>\n",
       "      <td>0.010963</td>\n",
       "      <td>0.015177</td>\n",
       "      <td>0.013968</td>\n",
       "      <td>0.014654</td>\n",
       "      <td>0.014541</td>\n",
       "      <td>ester</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120-33-2</td>\n",
       "      <td>0.001862</td>\n",
       "      <td>0.002358</td>\n",
       "      <td>0.000965</td>\n",
       "      <td>0.001367</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.002217</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007558</td>\n",
       "      <td>0.006625</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>0.004450</td>\n",
       "      <td>0.003911</td>\n",
       "      <td>0.003702</td>\n",
       "      <td>0.003551</td>\n",
       "      <td>0.002494</td>\n",
       "      <td>0.002388</td>\n",
       "      <td>ester</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120-51-4</td>\n",
       "      <td>0.011749</td>\n",
       "      <td>0.009791</td>\n",
       "      <td>0.006795</td>\n",
       "      <td>0.006387</td>\n",
       "      <td>0.006919</td>\n",
       "      <td>0.005475</td>\n",
       "      <td>0.004003</td>\n",
       "      <td>0.002257</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005814</td>\n",
       "      <td>0.004950</td>\n",
       "      <td>0.004097</td>\n",
       "      <td>0.003773</td>\n",
       "      <td>0.003183</td>\n",
       "      <td>0.002548</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>0.002459</td>\n",
       "      <td>0.002356</td>\n",
       "      <td>ester</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120650-77-3</td>\n",
       "      <td>0.004431</td>\n",
       "      <td>0.005630</td>\n",
       "      <td>0.005578</td>\n",
       "      <td>0.005711</td>\n",
       "      <td>0.004729</td>\n",
       "      <td>0.003658</td>\n",
       "      <td>0.004980</td>\n",
       "      <td>0.003962</td>\n",
       "      <td>0.003673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004496</td>\n",
       "      <td>0.005218</td>\n",
       "      <td>0.003233</td>\n",
       "      <td>0.006065</td>\n",
       "      <td>0.004307</td>\n",
       "      <td>0.004863</td>\n",
       "      <td>0.005305</td>\n",
       "      <td>0.003419</td>\n",
       "      <td>0.005081</td>\n",
       "      <td>ester</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1335-40-6</td>\n",
       "      <td>0.026083</td>\n",
       "      <td>0.025300</td>\n",
       "      <td>0.025201</td>\n",
       "      <td>0.024101</td>\n",
       "      <td>0.023793</td>\n",
       "      <td>0.022894</td>\n",
       "      <td>0.020080</td>\n",
       "      <td>0.016694</td>\n",
       "      <td>0.013240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005708</td>\n",
       "      <td>0.005478</td>\n",
       "      <td>0.005245</td>\n",
       "      <td>0.005083</td>\n",
       "      <td>0.005195</td>\n",
       "      <td>0.005259</td>\n",
       "      <td>0.005337</td>\n",
       "      <td>0.005369</td>\n",
       "      <td>0.005188</td>\n",
       "      <td>ester</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 727 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0       600       604       608       612       616       620  \\\n",
       "0    1119-40-0  0.009480  0.011373  0.008950  0.010881  0.012741  0.012765   \n",
       "1     120-33-2  0.001862  0.002358  0.000965  0.001367  0.001221  0.002217   \n",
       "2     120-51-4  0.011749  0.009791  0.006795  0.006387  0.006919  0.005475   \n",
       "3  120650-77-3  0.004431  0.005630  0.005578  0.005711  0.004729  0.003658   \n",
       "4    1335-40-6  0.026083  0.025300  0.025201  0.024101  0.023793  0.022894   \n",
       "\n",
       "        624       628       632  ...        3464      3468      3472  \\\n",
       "0  0.011669  0.010218  0.008583  ...    0.007078  0.007871  0.009175   \n",
       "1  0.001162  0.000631  0.001026  ...    0.007558  0.006625  0.004902   \n",
       "2  0.004003  0.002257  0.002252  ...    0.005814  0.004950  0.004097   \n",
       "3  0.004980  0.003962  0.003673  ...    0.004496  0.005218  0.003233   \n",
       "4  0.020080  0.016694  0.013240  ...    0.005708  0.005478  0.005245   \n",
       "\n",
       "       3476      3480      3484      3488      3492      3496  label  \n",
       "0  0.010160  0.010963  0.015177  0.013968  0.014654  0.014541  ester  \n",
       "1  0.004450  0.003911  0.003702  0.003551  0.002494  0.002388  ester  \n",
       "2  0.003773  0.003183  0.002548  0.002194  0.002459  0.002356  ester  \n",
       "3  0.006065  0.004307  0.004863  0.005305  0.003419  0.005081  ester  \n",
       "4  0.005083  0.005195  0.005259  0.005337  0.005369  0.005188  ester  \n",
       "\n",
       "[5 rows x 727 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv('NIST_selected_organic_spectra.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(405, 727)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape #check\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Apply multilabel  \n",
    "\n",
    "ref.: http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html\n",
    "\n",
    "- The labels are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ester', 'ketone', 'alcohol', 'alkane', 'alkene', 'amine',\n",
       "       'aldehyde', 'acid', 'halide', 'benzene'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the label names:\n",
    "df.label.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#we have nine labels:  \n",
    "#ref.: Brian C. Smith, \"Infrared Spectral Interpretation: A Systematic Approach\", CRC Press 1998.  \n",
    "#Note: Aldehydes have the characteristic C-H stretch, denoted here as C-H_ald to differentiate from ketones.  \n",
    "\n",
    "label_names=  \n",
    "['C-H', 'C=C', \\  #1,2    \n",
    "'C=O', 'C-O', \\  #3,4  \n",
    "'O-H', 'C-N', \\  #5,6  \n",
    "'N-H', 'C-X', \\  #7,8  \n",
    "'Ar', 'C-H_ald'] #9,10    \n",
    "\n",
    "Cheat-sheet:  \n",
    "    ester=(1,3,4,,,,,,)  \n",
    "    ketone=(1,3,,,,,,,)  \n",
    "    alcohol=(1,4,,,,,,,)  \n",
    "    alkane=(1,2,,,,,,,)  \n",
    "    alkene=(1,2,,,,,,,)  \n",
    "    amine=(1,6,7,,,,,,)  \n",
    "    aldehyde=(1,3,10,,,,,,)  \n",
    "    alcid=(1,3,4,5,,,,,)  \n",
    "    halide=(1,8,,,,,,,)  \n",
    "    benzene=(1,2,9,,,,,,)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1. define labels for each functional group as tuples.\n",
    "ester_label=[1,3,4]  \n",
    "ketone_label=[1,3]  \n",
    "alcohol_label=[1,4]  \n",
    "alkane_label=[1,2]  \n",
    "alkene_label=[1,2]  \n",
    "amine_label=[1,6,7]  \n",
    "aldehyde_label=[1,3,10]  \n",
    "acid_label=[1,3,4,5]  \n",
    "halide_label=[1,8]  \n",
    "benzene_label=[1,2,9]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, ..., 0, 0, 0],\n",
       "       [1, 0, 1, ..., 0, 0, 0],\n",
       "       [1, 0, 1, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [1, 1, 0, ..., 0, 1, 0],\n",
       "       [1, 1, 0, ..., 0, 1, 0],\n",
       "       [1, 1, 0, ..., 0, 1, 0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create labels\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer() #create object\n",
    "\n",
    "#generate as many labels as there are entries in the respective groups and the combine it into a single array with row number matching with the Dataset\n",
    "#https://stackoverflow.com/questions/19753279/repeat-a-tuple-inside-a-tuple\n",
    "y_label=len(df[df.label=='ester'])*[ester_label,] + \\\n",
    "        len(df[df.label=='ketone'])*[ketone_label,] + \\\n",
    "        len(df[df.label=='alcohol'])*[alcohol_label,] + \\\n",
    "        len(df[df.label=='alkane'])*[alkane_label,] + \\\n",
    "        len(df[df.label=='alkene'])*[alkene_label,] + \\\n",
    "        len(df[df.label=='amine'])*[amine_label,] + \\\n",
    "        len(df[df.label=='aldehyde'])*[aldehyde_label,] + \\\n",
    "        len(df[df.label=='acid'])*[acid_label,] + \\\n",
    "        len(df[df.label=='halide'])*[halide_label,] + \\\n",
    "        len(df[df.label=='benzene'])*[benzene_label,] \n",
    "\n",
    "y_label=mlb.fit_transform(y_label) #convert tuples list to multilabelbinarizer\n",
    "#len(y_label) #check\n",
    "y_label #check\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split datasets into train/test datasets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( \n",
    "    df.iloc[:,1:726], y_label, test_size=0.2, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#normalize datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler=StandardScaler().fit(X_train)\n",
    "standardized_X=scaler.transform(X_train)\n",
    "standardized_X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (II) Apply skmultilearn  \n",
    "ref.: https://www.analyticsvidhya.com/blog/2017/08/introduction-to-multi-label-classification/ \n",
    "\n",
    "- skmultilearn cannot be installed!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#to install skmultilearn: pip install scikit-multilearn\n",
    "##from skmultilearn.adapt import MLkNN\n",
    "\n",
    "##classifier = MLkNN(k=20)\n",
    "\n",
    "# train\n",
    "##classifier.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "##predictions = classifier.predict(X_test)\n",
    "\n",
    "##accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) kNNCLassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Using sklearn instead of skmultilearn because skmultilearn cannot be installed  \n",
    "\n",
    "apply multilabel algorithms: http://scikit-learn.org/stable/modules/multiclass.html \n",
    "\n",
    "sklearn.tree.DecisionTreeClassifier\n",
    "sklearn.tree.ExtraTreeClassifier\n",
    "sklearn.ensemble.ExtraTreesClassifier\n",
    "sklearn.neighbors.KNeighborsClassifier\n",
    "sklearn.neural_network.MLPClassifier\n",
    "sklearn.neighbors.RadiusNeighborsClassifier\n",
    "sklearn.ensemble.RandomForestClassifier\n",
    "sklearn.linear_model.RidgeClassifierCV\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=1)\n",
    "neigh.fit(standardized_X, y_train) \n",
    "\n",
    "#print(neigh.predict([[1.1]]))\n",
    "\n",
    "#print(neigh.predict_proba([[0.9]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62962962962962965"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh.score(standardized_X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, 0, 0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test:\n",
    "neigh.predict(standardized_X_test[0].reshape(1,725))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60493827160493829"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.datasets import make_classification\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=20, random_state=0)\n",
    "clf.fit(standardized_X, y_train)\n",
    "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
    "            oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "\n",
    "clf.score(standardized_X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Screen multiple models simultaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTR: 0.583333 (0.087615)\n",
      "ETC: 0.521780 (0.094644)\n",
      "ETC_E: 0.558523 (0.099360)\n",
      "KNC: 0.601610 (0.060275)\n",
      "RFC: 0.527746 (0.086014)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nf+g7kEFHS6zBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x158a7a4ce80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "sklearn.tree.DecisionTreeClassifier\n",
    "sklearn.tree.ExtraTreeClassifier\n",
    "sklearn.ensemble.ExtraTreesClassifier\n",
    "sklearn.neighbors.KNeighborsClassifier\n",
    "sklearn.neural_network.MLPClassifier\n",
    "sklearn.neighbors.RadiusNeighborsClassifier\n",
    "sklearn.ensemble.RandomForestClassifier\n",
    "sklearn.linear_model.RidgeClassifierCV\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Compare Algorithms\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#from sklearn.model_selection import KFold\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "#from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "#from sklearn.naive_bayes import GaussianNB\n",
    "#from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "\n",
    "\n",
    "# prepare models\n",
    "models = []\n",
    "models.append(('DTR', DecisionTreeClassifier())) \n",
    "models.append(('ETC', ExtraTreeClassifier()))\n",
    "models.append(('ETC_E', ExtraTreesClassifier()))\n",
    "models.append(('KNC', KNeighborsClassifier()))\n",
    "##models.append(('MLPC', MLPClassifier()))\n",
    "#models.append(('RNC', RadiusNeighborsClassifier()))\n",
    "models.append(('RFC', RandomForestClassifier()))\n",
    "#models.append(('RC', RidgeClassifierCV()))\n",
    "\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "\n",
    "\n",
    "for name, model in models: #iterate through each of the different models\n",
    "    #Use k-fold validation to determine model accuracy. k-fold validation is one of many ways, but it is the gold standard way.\n",
    "    try:\n",
    "        kfold = KFold(n_splits=10, random_state=7) #initiate k-fold validation. Here, we use 10-folds.\n",
    "        cv_results = cross_val_score(model, standardized_X, y_train, cv=kfold, scoring=scoring) #apply model in turns.\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "    except:\n",
    "        print('Error in:', name, 'and', model)\n",
    "        \n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "    \n",
    "# boxplot algorithm comparison\n",
    "fig = pyplot.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "pyplot.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (II) Apply PCA - Need to use onehotencoder!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Apply pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGsoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x158a6d50cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Perform pca\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca=PCA(n_components=20) #generate model\n",
    "\n",
    "X_pca=pca.fit_transform(df.iloc[:,1:726])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.plot(np.arange(20),pca.explained_variance_ratio_.cumsum())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split datasets into train/test datasets for PCA\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split( \n",
    "    X_pca, y_label, test_size=0.2, random_state=13)\n",
    "\n",
    "#normalize datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler=StandardScaler().fit(X_train_pca)\n",
    "standardized_X_pca=scaler.transform(X_train_pca)\n",
    "standardized_X_test_pca=scaler.transform(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69135802469135799"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model=KNeighborsClassifier(n_neighbors=5)\n",
    "model.fit(standardized_X_pca,y_train_pca)\n",
    "\n",
    "model.score(standardized_X_test_pca,y_test_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Apply pca and knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model=KNeighborsClassifier(n_neighbors=1)\n",
    "model.fit(standardized_X_pca,y_train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64197530864197527"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(standardized_X_test_pca,y_test_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Score is the same!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Tune n_component and n_neighbor simultaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Components =  5 , neighbors =  1 , Score =  0.567901234568\n",
      "Components =  5 , neighbors =  2 , Score =  0.444444444444\n",
      "Components =  5 , neighbors =  3 , Score =  0.506172839506\n",
      "Components =  5 , neighbors =  4 , Score =  0.456790123457\n",
      "Components =  5 , neighbors =  5 , Score =  0.481481481481\n",
      "Components =  5 , neighbors =  6 , Score =  0.444444444444\n",
      "Components =  5 , neighbors =  7 , Score =  0.469135802469\n",
      "Components =  10 , neighbors =  1 , Score =  0.666666666667\n",
      "Components =  10 , neighbors =  2 , Score =  0.604938271605\n",
      "Components =  10 , neighbors =  3 , Score =  0.654320987654\n",
      "Components =  10 , neighbors =  4 , Score =  0.62962962963\n",
      "Components =  10 , neighbors =  5 , Score =  0.62962962963\n",
      "Components =  10 , neighbors =  6 , Score =  0.555555555556\n",
      "Components =  10 , neighbors =  7 , Score =  0.555555555556\n",
      "Components =  15 , neighbors =  1 , Score =  0.641975308642\n",
      "Components =  15 , neighbors =  2 , Score =  0.592592592593\n",
      "Components =  15 , neighbors =  3 , Score =  0.691358024691\n",
      "Components =  15 , neighbors =  4 , Score =  0.592592592593\n",
      "Components =  15 , neighbors =  5 , Score =  0.641975308642\n",
      "Components =  15 , neighbors =  6 , Score =  0.604938271605\n",
      "Components =  15 , neighbors =  7 , Score =  0.617283950617\n",
      "Components =  20 , neighbors =  1 , Score =  0.641975308642\n",
      "Components =  20 , neighbors =  2 , Score =  0.567901234568\n",
      "Components =  20 , neighbors =  3 , Score =  0.654320987654\n",
      "Components =  20 , neighbors =  4 , Score =  0.641975308642\n",
      "Components =  20 , neighbors =  5 , Score =  0.691358024691\n",
      "Components =  20 , neighbors =  6 , Score =  0.617283950617\n",
      "Components =  20 , neighbors =  7 , Score =  0.617283950617\n",
      "Components =  25 , neighbors =  1 , Score =  0.641975308642\n",
      "Components =  25 , neighbors =  2 , Score =  0.567901234568\n",
      "Components =  25 , neighbors =  3 , Score =  0.654320987654\n",
      "Components =  25 , neighbors =  4 , Score =  0.641975308642\n",
      "Components =  25 , neighbors =  5 , Score =  0.691358024691\n",
      "Components =  25 , neighbors =  6 , Score =  0.617283950617\n",
      "Components =  25 , neighbors =  7 , Score =  0.617283950617\n",
      "Components =  30 , neighbors =  1 , Score =  0.641975308642\n",
      "Components =  30 , neighbors =  2 , Score =  0.567901234568\n",
      "Components =  30 , neighbors =  3 , Score =  0.654320987654\n",
      "Components =  30 , neighbors =  4 , Score =  0.641975308642\n",
      "Components =  30 , neighbors =  5 , Score =  0.691358024691\n",
      "Components =  30 , neighbors =  6 , Score =  0.617283950617\n",
      "Components =  30 , neighbors =  7 , Score =  0.617283950617\n"
     ]
    }
   ],
   "source": [
    "#Let's tune the knn n_neighbors parameter\n",
    "components = [5, 10, 15, 20, 25, 30] #optimize using up to 50 components\n",
    "neighbors = [1, 2, 3, 4, 5, 6, 7] #and using up to 7 neighbors\n",
    "\n",
    "scores = np.zeros( (components[len(components)-1]+1, neighbors[len(neighbors)-1]+1 ) )\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#show PCA scores as a function of neighbors, N, and no. of components\n",
    "for component in components:\n",
    "    for n in neighbors:\n",
    "        knn = KNeighborsClassifier(n_neighbors=n)\n",
    "        knn.fit(standardized_X_pca[:,:component], y_train_pca)\n",
    "        score = knn.score(standardized_X_test_pca[:,:component], y_test_pca)\n",
    "        #predict = knn.predict(X_test_pca[:,:component])\n",
    "        scores[component][n] = score\n",
    "        \n",
    "        print('Components = ', component, ', neighbors = ', n,', Score = ', score)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (III) Apply NN and CNN\n",
    "ref.: https://github.com/keras-team/keras/issues/741\n",
    "\n",
    "For multilabel classification, I am using sigmoid activation in place of softmax in the output layer and then use \"binary_crossentrpy\" loss.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# (III) Apply NN\n",
    "\n",
    "#import classes\n",
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "#establish random number\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "#define model\n",
    "num_pixels=725\n",
    "num_classes=10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NEED TO SOMEHOW FIX the onehotencoder, so the values don't change!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 324 samples, validate on 81 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.6462 - acc: 0.6633 - val_loss: 0.3299 - val_acc: 0.8889\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.2707 - acc: 0.9136 - val_loss: 0.2415 - val_acc: 0.9160\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.1812 - acc: 0.9429 - val_loss: 0.2115 - val_acc: 0.9296\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.1410 - acc: 0.9522 - val_loss: 0.1953 - val_acc: 0.9284\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.1127 - acc: 0.9611 - val_loss: 0.1853 - val_acc: 0.9432\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0917 - acc: 0.9685 - val_loss: 0.1779 - val_acc: 0.9457\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0775 - acc: 0.9747 - val_loss: 0.1711 - val_acc: 0.9469\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0669 - acc: 0.9787 - val_loss: 0.1660 - val_acc: 0.9457\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0591 - acc: 0.9799 - val_loss: 0.1612 - val_acc: 0.9457\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0524 - acc: 0.9836 - val_loss: 0.1577 - val_acc: 0.9494\n",
      "Baseline Error: 5.06%\n"
     ]
    }
   ],
   "source": [
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
    "    #https://datascience.stackexchange.com/questions/16182/multiple-output-classes-in-keras/16204#16204\n",
    "    model.add(Dense(num_classes, kernel_initializer='normal', activation='sigmoid')) #Can't use softmax, instead use sigmoid\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# build the model\n",
    "model = baseline_model()\n",
    "# Fit the model\n",
    "model.fit(standardized_X, y_train, validation_data=(standardized_X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(standardized_X_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(model.predict_on_batch(standardized_X[0].reshape(1,725)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### check model\n",
    "import decimal\n",
    "    \n",
    "check_model=standardized_X[0].reshape(1,725)\n",
    "np.round(model.predict(check_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.around(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  1.  0.  0.  0.  0.  0.  0.  1.]]\n",
      "[1 0 1 0 0 0 0 0 0 1]\n",
      "[[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "[1 0 0 0 0 1 1 0 0 0]\n",
      "[[ 1.  0.  0.  1.  0.  0.  0.  0.  0.  0.]]\n",
      "[1 0 0 1 0 0 0 0 0 0]\n",
      "[[ 1.  1.  0.  0.  0.  0.  0.  0.  1.  0.]]\n",
      "[1 1 0 0 0 0 0 0 1 0]\n",
      "[[ 1.  0.  0.  0.  0.  0.  0.  1.  0.  0.]]\n",
      "[1 0 0 0 0 0 0 1 0 0]\n",
      "[[ 1.  0.  1.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "[1 0 1 0 0 0 0 0 0 0]\n",
      "[[ 1.  0.  1.  0.  0.  0.  0.  0.  0.  1.]]\n",
      "[1 0 1 0 0 0 0 0 0 1]\n",
      "[[ 1.  0.  0.  0.  0.  0.  0.  1.  0.  0.]]\n",
      "[1 0 0 0 0 0 0 1 0 0]\n",
      "[[ 1.  1.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "[1 1 0 0 0 0 0 0 0 0]\n",
      "[[ 1.  0.  1.  1.  1.  0.  0.  0.  0.  0.]]\n",
      "[1 0 1 1 1 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "for i in range(20,30):\n",
    "    #print(i)\n",
    "    #print(np.around(model.predict(i.reshape(1,725))))\n",
    "    #print(np.around(model.predict(standardized_X[i].reshape(1,725))))\n",
    "    #print(y_test[i])\n",
    "    #print('\\n')\n",
    "    \n",
    "    print(np.around(model.predict(standardized_X[i].reshape(1,725))))\n",
    "    print(y_train[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "\n",
    "#https://keras.io/getting-started/sequential-model-guide/\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#first, need to re-shape the data\n",
    "standardized_X_cnn=standardized_X.reshape(324,1,25,29)\n",
    "standardized_X_test_cnn=standardized_X_test.reshape(81,1,25,29)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the larger model\n",
    "def larger_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(30, (5, 5), input_shape=(1, 25, 29), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(15, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='sigmoid')) #can't use softmax, instead use sigmoid\n",
    "    \n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 324 samples, validate on 81 samples\n",
      "Epoch 1/100\n",
      " - 3s - loss: 0.6420 - acc: 0.6509 - val_loss: 0.5783 - val_acc: 0.7605\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.5623 - acc: 0.7580 - val_loss: 0.5109 - val_acc: 0.8136\n",
      "Epoch 3/100\n",
      " - 2s - loss: 0.4965 - acc: 0.8222 - val_loss: 0.4630 - val_acc: 0.8272\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.4565 - acc: 0.8383 - val_loss: 0.4373 - val_acc: 0.8432\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.4389 - acc: 0.8500 - val_loss: 0.4139 - val_acc: 0.8543\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.4153 - acc: 0.8528 - val_loss: 0.3904 - val_acc: 0.8506\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.3949 - acc: 0.8537 - val_loss: 0.3770 - val_acc: 0.8617\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.3770 - acc: 0.8571 - val_loss: 0.3713 - val_acc: 0.8778\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.3712 - acc: 0.8599 - val_loss: 0.3639 - val_acc: 0.8765\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.3600 - acc: 0.8645 - val_loss: 0.3538 - val_acc: 0.8741\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.3463 - acc: 0.8682 - val_loss: 0.3441 - val_acc: 0.8679\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3314 - acc: 0.8738 - val_loss: 0.3346 - val_acc: 0.8753\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.3218 - acc: 0.8753 - val_loss: 0.3257 - val_acc: 0.8765\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3078 - acc: 0.8809 - val_loss: 0.3178 - val_acc: 0.8852\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.2962 - acc: 0.8880 - val_loss: 0.3107 - val_acc: 0.8938\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.2825 - acc: 0.8951 - val_loss: 0.3035 - val_acc: 0.8938\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.2762 - acc: 0.8975 - val_loss: 0.2930 - val_acc: 0.8975\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.2600 - acc: 0.9015 - val_loss: 0.2817 - val_acc: 0.8988\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.2459 - acc: 0.9025 - val_loss: 0.2717 - val_acc: 0.9012\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.2337 - acc: 0.9086 - val_loss: 0.2646 - val_acc: 0.8988\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-32e0ef843791>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel_cnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlarger_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel_cnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstandardized_X_cnn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstandardized_X_test_cnn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Final evaluation of the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\envs\\py35\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    891\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    892\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 893\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    895\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32mC:\\Anaconda2\\envs\\py35\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1629\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1630\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1631\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1632\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1633\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\Anaconda2\\envs\\py35\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1213\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1214\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\envs\\py35\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2330\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m   2331\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2332\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2333\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1124\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1125\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1321\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1306\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model_cnn = larger_model()\n",
    "# Fit the model\n",
    "model_cnn.fit(standardized_X_cnn, y_train, validation_data=(standardized_X_test_cnn, y_test), epochs=100, batch_size=200, verbose=2)\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores_cnn = model_cnn.evaluate(standardized_X_test_cnn, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores_cnn[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "check_cnn=standardized_X_test_cnn[0].reshape(1,1,25,29)\n",
    "np.round(model_cnn.predict(check_cnn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the answer seems off. How to make sure that the onehotencoder remain to be integers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Two issues:\n",
    "- fix onehot encoder in keras, si it remain categorical\n",
    "- utilize conv1D rather than conv2D."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
