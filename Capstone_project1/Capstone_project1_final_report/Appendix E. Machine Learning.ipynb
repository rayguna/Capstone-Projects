{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix E. Machine Learning\n",
    "\n",
    "The dataset consists of labelled IR spectra. Each spectrum is assigned to one or more labels, and the labels are not mutually exclusive. Therefore, we use multilabel classification techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Table of contents**\n",
    "#### &nbsp;&nbsp; (I) Import and prepare dataset\n",
    "#### &nbsp;&nbsp; (II) Apply a dimensionality reduction technique (i.e., PCA)\n",
    "#### &nbsp;&nbsp; (III) Screen multiple models simultaneously\n",
    "#### &nbsp;&nbsp; (IV) Optimize the parameters for DecisionTreesClassifier\n",
    "#### &nbsp;&nbsp; (V) Estimate score uncertainty with k-fold cross-validation\n",
    "#### &nbsp;&nbsp; (VI) Summary and next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (I) Import and prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>600</th>\n",
       "      <th>604</th>\n",
       "      <th>608</th>\n",
       "      <th>612</th>\n",
       "      <th>616</th>\n",
       "      <th>620</th>\n",
       "      <th>624</th>\n",
       "      <th>628</th>\n",
       "      <th>632</th>\n",
       "      <th>...</th>\n",
       "      <th>3464</th>\n",
       "      <th>3468</th>\n",
       "      <th>3472</th>\n",
       "      <th>3476</th>\n",
       "      <th>3480</th>\n",
       "      <th>3484</th>\n",
       "      <th>3488</th>\n",
       "      <th>3492</th>\n",
       "      <th>3496</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1119-40-0</td>\n",
       "      <td>0.009480</td>\n",
       "      <td>0.011373</td>\n",
       "      <td>0.008950</td>\n",
       "      <td>0.010881</td>\n",
       "      <td>0.012741</td>\n",
       "      <td>0.012765</td>\n",
       "      <td>0.011669</td>\n",
       "      <td>0.010218</td>\n",
       "      <td>0.008583</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007078</td>\n",
       "      <td>0.007871</td>\n",
       "      <td>0.009175</td>\n",
       "      <td>0.010160</td>\n",
       "      <td>0.010963</td>\n",
       "      <td>0.015177</td>\n",
       "      <td>0.013968</td>\n",
       "      <td>0.014654</td>\n",
       "      <td>0.014541</td>\n",
       "      <td>ester</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120-33-2</td>\n",
       "      <td>0.001862</td>\n",
       "      <td>0.002358</td>\n",
       "      <td>0.000965</td>\n",
       "      <td>0.001367</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.002217</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007558</td>\n",
       "      <td>0.006625</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>0.004450</td>\n",
       "      <td>0.003911</td>\n",
       "      <td>0.003702</td>\n",
       "      <td>0.003551</td>\n",
       "      <td>0.002494</td>\n",
       "      <td>0.002388</td>\n",
       "      <td>ester</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120-51-4</td>\n",
       "      <td>0.011749</td>\n",
       "      <td>0.009791</td>\n",
       "      <td>0.006795</td>\n",
       "      <td>0.006387</td>\n",
       "      <td>0.006919</td>\n",
       "      <td>0.005475</td>\n",
       "      <td>0.004003</td>\n",
       "      <td>0.002257</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005814</td>\n",
       "      <td>0.004950</td>\n",
       "      <td>0.004097</td>\n",
       "      <td>0.003773</td>\n",
       "      <td>0.003183</td>\n",
       "      <td>0.002548</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>0.002459</td>\n",
       "      <td>0.002356</td>\n",
       "      <td>ester</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120650-77-3</td>\n",
       "      <td>0.004431</td>\n",
       "      <td>0.005630</td>\n",
       "      <td>0.005578</td>\n",
       "      <td>0.005711</td>\n",
       "      <td>0.004729</td>\n",
       "      <td>0.003658</td>\n",
       "      <td>0.004980</td>\n",
       "      <td>0.003962</td>\n",
       "      <td>0.003673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004496</td>\n",
       "      <td>0.005218</td>\n",
       "      <td>0.003233</td>\n",
       "      <td>0.006065</td>\n",
       "      <td>0.004307</td>\n",
       "      <td>0.004863</td>\n",
       "      <td>0.005305</td>\n",
       "      <td>0.003419</td>\n",
       "      <td>0.005081</td>\n",
       "      <td>ester</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1335-40-6</td>\n",
       "      <td>0.026083</td>\n",
       "      <td>0.025300</td>\n",
       "      <td>0.025201</td>\n",
       "      <td>0.024101</td>\n",
       "      <td>0.023793</td>\n",
       "      <td>0.022894</td>\n",
       "      <td>0.020080</td>\n",
       "      <td>0.016694</td>\n",
       "      <td>0.013240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005708</td>\n",
       "      <td>0.005478</td>\n",
       "      <td>0.005245</td>\n",
       "      <td>0.005083</td>\n",
       "      <td>0.005195</td>\n",
       "      <td>0.005259</td>\n",
       "      <td>0.005337</td>\n",
       "      <td>0.005369</td>\n",
       "      <td>0.005188</td>\n",
       "      <td>ester</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 727 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0       600       604       608       612       616       620  \\\n",
       "0    1119-40-0  0.009480  0.011373  0.008950  0.010881  0.012741  0.012765   \n",
       "1     120-33-2  0.001862  0.002358  0.000965  0.001367  0.001221  0.002217   \n",
       "2     120-51-4  0.011749  0.009791  0.006795  0.006387  0.006919  0.005475   \n",
       "3  120650-77-3  0.004431  0.005630  0.005578  0.005711  0.004729  0.003658   \n",
       "4    1335-40-6  0.026083  0.025300  0.025201  0.024101  0.023793  0.022894   \n",
       "\n",
       "        624       628       632  ...        3464      3468      3472  \\\n",
       "0  0.011669  0.010218  0.008583  ...    0.007078  0.007871  0.009175   \n",
       "1  0.001162  0.000631  0.001026  ...    0.007558  0.006625  0.004902   \n",
       "2  0.004003  0.002257  0.002252  ...    0.005814  0.004950  0.004097   \n",
       "3  0.004980  0.003962  0.003673  ...    0.004496  0.005218  0.003233   \n",
       "4  0.020080  0.016694  0.013240  ...    0.005708  0.005478  0.005245   \n",
       "\n",
       "       3476      3480      3484      3488      3492      3496  label  \n",
       "0  0.010160  0.010963  0.015177  0.013968  0.014654  0.014541  ester  \n",
       "1  0.004450  0.003911  0.003702  0.003551  0.002494  0.002388  ester  \n",
       "2  0.003773  0.003183  0.002548  0.002194  0.002459  0.002356  ester  \n",
       "3  0.006065  0.004307  0.004863  0.005305  0.003419  0.005081  ester  \n",
       "4  0.005083  0.005195  0.005259  0.005337  0.005369  0.005188  ester  \n",
       "\n",
       "[5 rows x 727 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv('data/NIST_selected_organic_spectra.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(405, 727)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape #check\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Apply multilabel  \n",
    "\n",
    "ref.: http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html\n",
    "\n",
    "- The labels are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ester', 'ketone', 'alcohol', 'alkane', 'alkene', 'amine',\n",
       "       'aldehyde', 'acid', 'halide', 'benzene'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the label names:\n",
    "df.label.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#ref.: Brian C. Smith, \"Infrared Spectral Interpretation: A Systematic Approach\", CRC Press 1998.  \n",
    "#we have ten labels:  \n",
    "#Note: Aldehydes have the characteristic C-H stretch, denoted here as C-H_ald to differentiate from ketones.  \n",
    "\n",
    "label_names=  \n",
    "['C-H', 'C=C', \\  #1,2    \n",
    "'C=O', 'C-O', \\  #3,4  \n",
    "'O-H', 'C-N', \\  #5,6  \n",
    "'N-H', 'C-X', \\  #7,8  \n",
    "'Ar', 'C-H_ald'] #9,10    \n",
    "\n",
    "Cheat-sheet:  \n",
    "    ester=(1,3,4,,,,,,)  \n",
    "    ketone=(1,3,,,,,,,)  \n",
    "    alcohol=(1,4,5,,,,,)  \n",
    "    alkane=(1,,,,,,,,)  \n",
    "    alkene=(1,2,,,,,,,)  \n",
    "    amine=(1,6,7,,,,,,)  \n",
    "    aldehyde=(1,3,10,,,,,,)  \n",
    "    alcid=(1,3,4,5,,,,,)  \n",
    "    halide=(1,8,,,,,,,)  \n",
    "    benzene=(1,2,9,,,,,,)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1. define labels for each functional group as a list.\n",
    "ester_label=[1,3,4]  \n",
    "ketone_label=[1,3]  \n",
    "alcohol_label=[1,4,5]  \n",
    "alkane_label=[1]  \n",
    "alkene_label=[1,2]  \n",
    "amine_label=[1,6,7]  \n",
    "aldehyde_label=[1,3,10]  \n",
    "acid_label=[1,3,4,5]  \n",
    "halide_label=[1,8]  \n",
    "benzene_label=[1,2,9]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, ..., 0, 0, 0],\n",
       "       [1, 0, 1, ..., 0, 0, 0],\n",
       "       [1, 0, 1, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [1, 1, 0, ..., 0, 1, 0],\n",
       "       [1, 1, 0, ..., 0, 1, 0],\n",
       "       [1, 1, 0, ..., 0, 1, 0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create labels\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer() #create object\n",
    "\n",
    "#generate as many labels as there are entries in the respective groups and the combine it into a single array with row number matching with the Dataset\n",
    "#https://stackoverflow.com/questions/19753279/repeat-a-tuple-inside-a-tuple\n",
    "y_label=len(df[df.label=='ester'])*[ester_label,] + \\\n",
    "        len(df[df.label=='ketone'])*[ketone_label,] + \\\n",
    "        len(df[df.label=='alcohol'])*[alcohol_label,] + \\\n",
    "        len(df[df.label=='alkane'])*[alkane_label,] + \\\n",
    "        len(df[df.label=='alkene'])*[alkene_label,] + \\\n",
    "        len(df[df.label=='amine'])*[amine_label,] + \\\n",
    "        len(df[df.label=='aldehyde'])*[aldehyde_label,] + \\\n",
    "        len(df[df.label=='acid'])*[acid_label,] + \\\n",
    "        len(df[df.label=='halide'])*[halide_label,] + \\\n",
    "        len(df[df.label=='benzene'])*[benzene_label,] \n",
    "\n",
    "y_label=mlb.fit_transform(y_label) #convert tuples list to multilabelbinarizer\n",
    "#len(y_label) #check\n",
    "y_label #check\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (II) Screen various techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1. split datasets into train/test datasets for PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( \n",
    "    df.iloc[:,1:726], y_label, test_size=0.2, random_state=13)\n",
    "\n",
    "#2. normalize datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler=StandardScaler().fit(X_train)\n",
    "standardized_X=scaler.transform(X_train)\n",
    "standardized_X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTC: 0.530871 (0.076539)\n",
      "ETC: 0.413447 (0.046810)\n",
      "KNC: 0.548864 (0.082087)\n",
      "ETC_E: 0.496875 (0.099581)\n",
      "RFC: 0.518182 (0.078967)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2bb778ffb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare Algorithms\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# prepare models\n",
    "models = []\n",
    "models.append(('DTC', DecisionTreeClassifier())) \n",
    "models.append(('ETC', ExtraTreeClassifier()))\n",
    "models.append(('KNC', KNeighborsClassifier()))\n",
    "models.append(('ETC_E', ExtraTreesClassifier()))\n",
    "models.append(('RFC', RandomForestClassifier()))\n",
    "\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "\n",
    "\n",
    "for name, model in models: #iterate through each of the different models\n",
    "    #Use k-fold validation to determine model accuracy. k-fold validation is one of many ways, but it is the gold standard way.\n",
    "    try:\n",
    "        kfold = KFold(n_splits=10, random_state=7) #initiate k-fold validation. Here, we use 10-folds.\n",
    "        cv_results = cross_val_score(model, standardized_X, y_train, cv=kfold, scoring=scoring) #apply model in turns.\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "    except:\n",
    "        print('Error in:', name, 'and', model)\n",
    "        \n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "    \n",
    "# boxplot algorithm comparison\n",
    "fig = pyplot.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "pyplot.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  It is seen that DecisionTreeClassifier yields the highest score of about 0.55 and a relatively narrow standard deviation.\n",
    "- Next, I will utilize dimensionality reduction technique and simultaneously perform a hyperparameter tuning on this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (III) Apply a dimensionality reduction technique (i.e., PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzVYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2bb77ff6ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Perform pca\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "no_components=100\n",
    "\n",
    "pca=PCA(n_components=no_components) #generate model\n",
    "\n",
    "X_pca=pca.fit_transform(df.iloc[:,1:726])\n",
    "\n",
    "#combine X_pca and y_label into a single dataframe and export to a csv file\n",
    "#export the CAS index column as well\n",
    "df_X_PCA_y_label=pd.DataFrame(X_pca) #create a DataFrame\n",
    "df_X_PCA_y_label=pd.concat([df_X_PCA_y_label,pd.DataFrame(y_label)], axis=1)\n",
    "df_X_PCA_y_label=pd.concat([df_X_PCA_y_label,df.iloc[:,0]], axis=1) #CAS number column\n",
    "\n",
    "df_X_PCA_y_label.to_csv('data/df_X_PCA_y_label.csv', index=False)\n",
    "\n",
    "#save pca model with pickle, so that it can be retrieved later\n",
    "from pickle import dump\n",
    "\n",
    "filename='data/pca_model.sav'\n",
    "dump(pca,open(filename,'wb'))\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.plot(np.arange(no_components),100*pca.explained_variance_ratio_.cumsum())\n",
    "\n",
    "plt.xlabel('n_components')\n",
    "plt.ylabel('% Variation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The above plot shows that n_component=100 is sufficient to capture close to 100% of all variations. Below, we will carry out hyperparameter tuning to determine the optimum parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IV) Optimize the parameters for DecisionTreesClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1. split datasets into train/test datasets for PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split( \n",
    "    X_pca, y_label, test_size=0.2, random_state=13)\n",
    "\n",
    "#2. scale datasets\n",
    "scaler=StandardScaler().fit(X_train_pca)\n",
    "standardized_X_pca=scaler.transform(X_train_pca)\n",
    "standardized_X_test_pca=scaler.transform(X_test_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) DecisionTreesClassifier\n",
    "- Tune n_component and max_depth simultaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding the best parameters, please wait...\n",
      "\n",
      "\n",
      "Best score: ('components = ', 20, ', max_depth = ', 10, ', Score = ', 0.59259259259259256)\n"
     ]
    }
   ],
   "source": [
    "#Let's tune the parameters for DecisionTreeClassifier\n",
    "components = [5, 10, 15, 20, 25, 30, 50, 100] #optimize using up to 100 components\n",
    "max_depth = [10, 50, 100, 150, 200, 250] \n",
    "\n",
    "dtc_score=0 #temporarily stores previous score to be used to compare current with previous score\n",
    "dtc_best=\" \" #a list for storing the best parameter for the knn model\n",
    "\n",
    "print('Finding the best parameters, please wait...')\n",
    "\n",
    "DecisionTreeClassifier()\n",
    "\n",
    "for component in components:\n",
    "    for n in max_depth:\n",
    "        dtc = DecisionTreeClassifier(max_depth=n, random_state=0)\n",
    "        dtc.fit(standardized_X_pca[:,:component], y_train_pca)\n",
    "        score = dtc.score(standardized_X_test_pca[:,:component], y_test)\n",
    "        \n",
    "        if score>dtc_score:\n",
    "            dtc_score=score\n",
    "            dtc_best='components = ', component, ', max_depth = ', n,', Score = ', score\n",
    "        \n",
    "        #print('components = ', component, ', estimators = ', n,', Score = ', score)  \n",
    "\n",
    "            \n",
    "print('\\n')\n",
    "print('Best score:', dtc_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The highest score is 59% (components =  20 , max_depth =  10). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (V) Estimate score uncertainty with k-fold cross-validation\n",
    "\n",
    "The ensemble methods perform similarly with DecisionTreeClassifier to give a score of about 60%. To determine the score uncertainty, I carry out k-fold cross-validation using the best-found parameters.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate DecisionTreeClassifier using k-fold cross-validation \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#combine scaled datasets\n",
    "X=np.concatenate((standardized_X_pca,standardized_X_test_pca),axis=0)\n",
    "Y=np.concatenate((y_train_pca,y_test_pca),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 56.280% (5.786%)\n"
     ]
    }
   ],
   "source": [
    "n=10\n",
    "component=28\n",
    "\n",
    "num_folds = 10\n",
    "seed = 7\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "\n",
    "etc = DecisionTreeClassifier(max_depth=n, random_state=0)\n",
    "results = cross_val_score(etc, X[:,:component], Y, cv=kfold)\n",
    "\n",
    "print(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Therefore, the score accuracy of DecisionTreeClassifier model is 56.28 ± 5.79%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### (VI) Summary and next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Five machine learning models that are suitable for multilabel classification problems are assessed (i.e., DecisionTreeClassifier, ExtraTreeClassifier, ExtraTreesClassifier,  KNeighborsClassifier, and RandomForestClassifier).\n",
    "- Initial screening reveals that DecisionTreeClassifier better than the other four algorithms with an accuracy score of about 55%. \n",
    "- Next, I utilize dimensionality reduction techniques (i.e., PCA) along with DecisionTreeClassifier to optimize the parameter in the model.The best score that is achieved is 59% (Components = 20 , max_depth = 10). This is a very modest score.  \n",
    "- By carrying out k-fold cross-validation, the uncertainty in the score for DecisionTreeClassifier is 56.28 ± 5.79%.\n",
    "- To further improve the model accuracy, next I consider a neural network model to achieve an accuracy score that is better than 56.28 ± 5.79% (see <b>Appendix F</b>). \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
