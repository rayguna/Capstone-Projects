{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix B. Python Files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reusable functions are stored in two python files, namely my_jcamp.py and common.py. my_jcamp is taken from https://pypi.python.org/pypi/jcamp. This file reads a jcamp file and stores all information into a dictionary. Refer to the link provided for more details. Descriptions on each function in my_jcamp and common.py are described below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "**Table of contents**   \n",
    "#### &nbsp;&nbsp; I. my_jcamp.py\n",
    "\n",
    "#### &nbsp;&nbsp; II. common.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. my_jcamp.py\n",
    "\n",
    "Below describes some of the often used methods in my_jcamp class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JCAMP_reader(filename):\n",
    "    \n",
    "    '''\n",
    "    Uses jcamp_read() function to read a JDX-format file and return a dictionary containing the header info, a 1D numpy \n",
    "    vectors `x` for\n",
    "    the abscissa information (e.g. wavelength or wavenumber) and `y` for the ordinate information (e.g.\n",
    "    transmission).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filehandle : str\n",
    "        The object representing the JCAMP-DX filename to read.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    jcamp_dict : dict\n",
    "        The dictionary containing the header and data vectors.\n",
    "    '''\n",
    "\n",
    "JCAMP_calc_xsec(jcamp_dict, wavemin=None, wavemax=None, skip_nonquant=True, debug=False)\n",
    "\n",
    "    '''\n",
    "    Taking as input a JDX file, extract the spectrum information and transform the absorption spectrum\n",
    "    from existing units to absorption cross-section.\n",
    "\n",
    "    This function also corrects for unphysical data (such as negative transmittance values, or\n",
    "    transmission above 1.0), and calculates absorbance if transmittance given. Instead of a return\n",
    "    value, the function inserts the information into the input dictionary.\n",
    "\n",
    "    Note that the conversion assumes that the measurements were collected for gas at a temperature of\n",
    "    296K (23 degC).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    jcamp_dict : dict\n",
    "        A JCAMP spectrum dictionary.\n",
    "    wavemin : float, optional\n",
    "        The shortest wavelength in the spectrum to limit the calculation to.\n",
    "    wavemax : float, optional\n",
    "        The longest wavelength in the spectrum to limit the calculation to.\n",
    "    skip_nonquant: bool\n",
    "        If True then return \"None\" if the spectrum is missing quantitative data. If False, then try \\\n",
    "        to fill in missing quantitative values with defaults.\n",
    "    '''\n",
    "\n",
    "is_float(s):\n",
    "\n",
    "    '''\n",
    "    Test if a string, or list of strings, contains a numeric value(s).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    s : str, or list of str\n",
    "        The string or list of strings to test.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    is_float_bool : bool or list of bool\n",
    "        A single boolean or list of boolean values indicating whether each input can be converted into a float.\n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. common.py\n",
    "\n",
    "Below describes all of the functions within common.py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create_periodic_table(file_name)\n",
    "\n",
    "    ''' \n",
    "    Read a text file line-by-line and extract information for: atomic number, atomic symbol, and relative atomic mass \n",
    "\n",
    "    The author is aware of at least one python periodic elements package (e.g., \n",
    "    https://pypi.python.org/pypi/periodictable), but chose to implement a different approach.\n",
    "    '''\n",
    "\n",
    "extract_unique_elements(df)\n",
    "\n",
    "    '''\n",
    "    Given a pandas DataFrame containing a column of chemical formula, return the DataFrame \n",
    "    with an additional column containing unique elements in the formula called df['Elements']\n",
    "    \n",
    "    Args:\n",
    "    df_Formula=a column of chemical formula in a pandas DataFrame\n",
    "    \n",
    "    Return:\n",
    "    a list of unique elements\n",
    "    '''\n",
    "\n",
    "shorten_df_by_elements_list(df_el, elements_list, all_or_any)\n",
    "\n",
    "    '''\n",
    "    Reduce number of entries in DataFrame by keeping only those that contain elements indicated on elements_list\n",
    "    \n",
    "    Args:\n",
    "    df_el=the DataFrame containing the distinct elements in each entry\n",
    "    all_or_any=specify if the output DataFrame should contain all or any of the elements indicated on elements_list\n",
    "    \n",
    "    Returns:\n",
    "    df_el_filt=pandas DataFrame\n",
    "    '''\n",
    "\n",
    "calc_molec_weight(nist_chem_list, periodic_table)\n",
    "\n",
    "    '''\n",
    "    Calculate molecular weight, Mw, given a chemical formula, df.Formula \n",
    "    #ref.: https://stackoverflow.com/questions/41818916/calculate-molecular-weight-based-on-chemical-formula-using-python\n",
    "\n",
    "    Args:\n",
    "    nist_chem_list=a pandas DataFrame from which Mw will be calculated.\n",
    "    periodic_table=a periodic table dictionary from which the atomic weight of each element can be retrieved.\n",
    "\n",
    "    Returns:\n",
    "    the same dataframe, but with an extra column added. This extra column is labelled as 'Mw'.\n",
    "    '''\n",
    "    \n",
    "standardize_units(jcamp_dict)\n",
    "        \n",
    "    '''\n",
    "    Given a jcamp dictionary, standardize x and y units to 1/cm and absorbance, respectively and return a modified \n",
    "    dictionary. \n",
    "    \n",
    "    Args:\n",
    "    jcamp_dict=a jcamp dictionary    \n",
    "    \n",
    "    Returns:\n",
    "    jcamp_dict=a modified jcamp dictionary   \n",
    "    '''\n",
    "\n",
    "'''\n",
    "#baseline subtraction function\n",
    "#ref.: https://raw.githubusercontent.com/zmzhang/airPLS/master/airPLS.py\n",
    "\n",
    "#!/usr/bin/python\n",
    "\n",
    "airPLS.py Copyright 2014 Renato Lombardo - renato.lombardo@unipa.it\n",
    "Baseline correction using adaptive iteratively reweighted penalized least squares\n",
    "\n",
    "This program is a translation in python of the R source code of airPLS version 2.0\n",
    "by Yizeng Liang and Zhang Zhimin - https://code.google.com/p/airpls\n",
    "Reference:\n",
    "Z.-M. Zhang, S. Chen, and Y.-Z. Liang, Baseline correction using adaptive iteratively reweighted penalized least squares. Analyst 135 (5), 1138-1146 (2010).\n",
    "\n",
    "Description from the original documentation:\n",
    "\n",
    "Baseline drift always blurs or even swamps signals and deteriorates analytical results, particularly in multivariate analysis.  It is necessary to correct baseline drift to perform further data analysis. Simple or modified polynomial fitting has been found to be effective in some extent. However, this method requires user intervention and prone to variability especially in low signal-to-noise ratio environments. The proposed adaptive iteratively reweighted Penalized Least Squares (airPLS) algorithm doesn't require any user intervention and prior information, such as detected peaks. It iteratively changes weights of sum squares errors (SSE) between the fitted baseline and original signals, and the weights of SSE are obtained adaptively using between previously fitted baseline and original signals. This baseline estimator is general, fast and flexible in fitting baseline.\n",
    "\n",
    "\n",
    "LICENCE\n",
    "This program is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU Lesser General Public License as published by\n",
    "the Free Software Foundation, either version 3 of the License, or\n",
    "(at your option) any later version.\n",
    "\n",
    "This program is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU Lesser General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU Lesser General Public License\n",
    "along with this program.  If not, see <http://www.gnu.org/licenses/>\n",
    "'''\n",
    "\n",
    "\n",
    "WhittakerSmooth(x,w,lambda_,differences=1)\n",
    "\n",
    "    '''\n",
    "    Penalized least squares algorithm for background fitting\n",
    "    \n",
    "    input\n",
    "    x: input data (i.e. chromatogram of spectrum)\n",
    "    w: binary masks (value of the mask is zero if a point belongs to peaks and one otherwise)\n",
    "    lambda_: parameter that can be adjusted by user. The larger lambda is,  the smoother the resulting background\n",
    "    differences: integer indicating the order of the difference of penalties\n",
    "    \n",
    "    output\n",
    "    the fitted background vector\n",
    "    '''\n",
    "airPLS(x, lambda_=100, porder=1, itermax=15)\n",
    "\n",
    "    '''\n",
    "    Adaptive iteratively reweighted penalized least squares for baseline fitting\n",
    "    \n",
    "    input\n",
    "    x: input data (i.e. chromatogram of spectrum)\n",
    "    lambda_: parameter that can be adjusted by user. The larger lambda is,  the smoother the resulting background, z\n",
    "    porder: adaptive iteratively reweighted penalized least squares for baseline fitting\n",
    "    \n",
    "    output\n",
    "    the fitted background vector\n",
    "    '''\n",
    "\n",
    "baseline_subtract(data_dict)\n",
    "\n",
    "    '''\n",
    "    Given a jcamp dictionary, this function performs a baseline subtraction\n",
    "    \n",
    "    Args:\n",
    "    data_dict=a dictionary that is generated using my_jcamp.py from a jcamp file.\n",
    "    \n",
    "    Return:\n",
    "    data_dict=a dictionary of treated spectrum.    \n",
    "    '''\n",
    "\n",
    "def treat_spectra(data_dict)\n",
    "\n",
    "    '''\n",
    "    Uniformize spectra units (x- and y-axes) to make them all comparable with one another.\n",
    "    \n",
    "    Args:\n",
    "    data_dict=a dictionary that is generated using my_jcamp.py from a jcamp file.\n",
    "    \n",
    "    Return:\n",
    "    data_dict=a dictionary of treated spectrum.\n",
    "    '''\n",
    "\n",
    "pick_peaks(compound_name, x, y)\n",
    "\n",
    "    '''\n",
    "    Identify peaks maxima. This algorithm is a 1-D search. It doesn't account for the x-values.\n",
    "    ref.: #https://stackoverflow.com/questions/31016267/peak-detection-in-python-how-does-the-scipy-signal-find-peaks-cwt-\n",
    "    function-work\n",
    "        \n",
    "    Args:\n",
    "    compound_name=to be used asa title in the generated plot (string).\n",
    "    x=x-values (list)\n",
    "    y=y-values (list)\n",
    "    \n",
    "    Returns:\n",
    "    uses peakutils package to pick peaks in 1-D and plot out the x,y values, along with the identified peak maxima.\n",
    "    '''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
